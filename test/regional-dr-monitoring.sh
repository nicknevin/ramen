#!/bin/bash
# SPDX-FileCopyrightText: The RamenDR authors
# SPDX-License-Identifier: Apache-2.0

# Enhanced RamenDR Regional DR Monitoring Script  
# Comprehensive real-time monitoring for multi-cluster CSI replication testing

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Check contexts for regional DR environment
check_contexts() {
    if [ -z "$KUBECONFIG" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  KUBECONFIG not set, setting to default: ~/.kube/config${NC}"
        export KUBECONFIG=~/.kube/config
    fi
    
    local required_contexts=("hub" "dr1")
    local optional_contexts=("dr2")
    
    for ctx in "${required_contexts[@]}"; do
        if ! kubectl config get-contexts -o name | grep -q "^$ctx$"; then
            echo -e "${RED}‚ùå Required context '$ctx' not found${NC}"
            echo "Available contexts:"
            kubectl config get-contexts -o name
            echo ""
            echo -e "${YELLOW}üí° To fix missing contexts, try:${NC}"
            echo "  minikube start --profile=$ctx"
            echo "  minikube update-context --profile=$ctx"
            exit 1
        fi
    done
    
    # Check optional contexts
    local found_contexts="hub, dr1"
    for ctx in "${optional_contexts[@]}"; do
        if kubectl config get-contexts -o name | grep -q "^$ctx$"; then
            found_contexts="$found_contexts, $ctx"
        else
            echo -e "${YELLOW}‚ö†Ô∏è  Optional context '$ctx' not found (cluster may be stopped)${NC}"
        fi
    done
    
    echo -e "${GREEN}‚úÖ Available contexts: $found_contexts${NC}"
}

# Enhanced monitoring function
comprehensive_monitoring() {
    clear
    echo "KUBECONFIG: $KUBECONFIG"
    echo "CURRENT_CONTEXT: $(kubectl config current-context 2>/dev/null || echo 'No context set')"

    echo -e "${GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
    echo -e "${GREEN}                  üîç RAMENDR REGIONAL DR CSI MONITORING                        ${NC}"
    echo -e "${GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
    echo ""
    
    # Timestamp
    echo -e "${CYAN}üìÖ $(date '+%Y-%m-%d %H:%M:%S')${NC}"
    echo ""

    # CLUSTER INFRASTRUCTURE
    echo -e "${BLUE}=== CLUSTER INFRASTRUCTURE ===${NC}"
    echo "üèóÔ∏è Contexts:"
    kubectl config get-contexts | head -n 1  # Header
    kubectl config get-contexts | grep -E "(hub|dr1|dr2)" || echo "  No regional DR contexts found"
    echo ""
    
    # RAMENDR OPERATORS
    echo -e "${YELLOW}=== RAMENDR OPERATORS ===${NC}"
    echo "Hub Operator:"
    kubectl --context=hub get pods -n ramen-system 2>/dev/null || echo "  Hub cluster not accessible"
    echo "DR1 Operator:" 
    kubectl --context=dr1 get pods -n ramen-system 2>/dev/null || echo "  DR1 cluster not accessible"
    if kubectl config get-contexts -o name | grep -q "^dr2$"; then
        echo "DR2 Operator:" 
        kubectl --context=dr2 get pods -n ramen-system 2>/dev/null || echo "  DR2 cluster not accessible"
    else
        echo "DR2 Operator: (cluster not available)"
    fi
    echo ""

    # ORCHESTRATION LAYER (Hub)
    echo -e "${PURPLE}=== ORCHESTRATION LAYER (HUB) ===${NC}"
    echo "üåê ManagedClusters:"
    kubectl --context=hub get managedcluster -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No managedclusters found"
    echo "üìã DRPolicy:"
    kubectl --context=hub get drpolicy -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No DRPolicies found"
    echo "üéØ DRPlacement (DRPC):"
    kubectl --context=hub get drplacementcontrol --all-namespaces -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No DRPCs found"
    echo ""
    echo "üéØ PlacementDecision:"
    kubectl --context=hub get placementdecision --all-namespaces -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No PlacementDecisions found"
    echo ""
    echo "üè¢ DRClusters:"
    kubectl --context=hub get drcluster -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No DRClusters found"
    echo ""

    # PROTECTION LAYER (DR)
    echo -e "${CYAN}=== PROTECTION LAYER (DR CLUSTERS) ===${NC}"
    echo "üì¶ VolumeReplicationGroups (DR1):"
    kubectl --context=dr1 get vrg -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No VRGs found on dr1"
    echo "üì¶ VolumeReplicationGroups (DR2):"
    kubectl --context=dr2 get vrg -A -o wide 2>/dev/null | grep -v "No resources" || echo "  No VRGs found on dr2"
    echo "üîÑ VolumeReplication (DR1):" 
    kubectl --context=dr1 get volumereplication --all-namespaces -o wide 2>/dev/null | grep -v "No resources" || echo "  No VolumeReplications found"
    echo ""

    # STORAGE INFRASTRUCTURE
    echo -e "${GREEN}=== CSI & STORAGE INFRASTRUCTURE ===${NC}"
    echo "üìÇ VolumeReplicationClass (DR1):"
    kubectl --context=dr1 get volumereplicationclass -o wide 2>/dev/null | grep -v "No resources" || echo "  No VolumeReplicationClasses found"
    echo "üì∏ VolumeSnapshotClass (DR1):"
    kubectl --context=dr1 get volumesnapshotclass -o wide 2>/dev/null | grep -v "No resources" || echo "  No VolumeSnapshotClasses found"
    echo "üíæ StorageClass (DR1):"
    kubectl --context=dr1 get storageclass 2>/dev/null || echo "  No StorageClasses found"
    echo "üíæ StorageClass (DR2):"
    kubectl --context=dr2 get storageclass 2>/dev/null || echo "  No StorageClasses found"
    echo ""

    # CEPH STORAGE STATUS
    echo -e "${CYAN}=== CEPH STORAGE STATUS ===${NC}"
    echo "üèóÔ∏è Ceph Cluster (DR1):"
    kubectl --context=dr1 -n rook-ceph get cephcluster -o wide 2>/dev/null || echo "  No CephCluster found on dr1"
    echo "üèóÔ∏è Ceph Cluster (DR2):"
    kubectl --context=dr2 -n rook-ceph get cephcluster -o wide 2>/dev/null || echo "  No CephCluster found on dr2"
    echo "üíæ Ceph BlockPool (DR1):"
    kubectl --context=dr1 -n rook-ceph get cephblockpool -o wide 2>/dev/null || echo "  No CephBlockPool found on dr1"
    echo "üíæ Ceph BlockPool (DR2):"
    kubectl --context=dr2 -n rook-ceph get cephblockpool -o wide 2>/dev/null || echo "  No CephBlockPool found on dr2"
    echo ""

    # RBD MIRROR STATUS
    echo -e "${YELLOW}=== RBD MIRRORING STATUS ===${NC}"
    echo "ü™û RBD Mirror (DR1):"
    kubectl --context=dr1 -n rook-ceph get deployment rook-ceph-rbd-mirror-a 2>/dev/null || echo "  RBD Mirror not found on dr1"
    echo "ü™û RBD Mirror (DR2):"
    kubectl --context=dr2 -n rook-ceph get deployment rook-ceph-rbd-mirror-a 2>/dev/null || echo "  RBD Mirror not found on dr2"
    echo ""

    # APPLICATION STATUS
    echo -e "${PURPLE}=== PROTECTED APPLICATIONS ===${NC}"
    echo "üöÄ Test Applications (DR1):"
    kubectl --context=dr1 get pods,pvc -A | grep -E "(test|demo|sample)" | head -5 || echo "  No test applications found on dr1"
    echo "üöÄ Test Applications (DR2):"
    kubectl --context=dr2 get pods,pvc -A | grep -E "(test|demo|sample)" | head -5 || echo "  No test applications found on dr2"
    echo ""

    # S3 BACKUP STATUS
    echo -e "${BLUE}=== S3 BACKUP INFRASTRUCTURE ===${NC}"
    echo "ü™£ S3 MinIO Status (Hub):"
    kubectl --context=hub get pods,svc -n minio-system 2>/dev/null | grep -v "No resources" || echo "  MinIO not found in hub cluster"
    echo "ü™£ S3 MinIO Status (DR1):"
    kubectl --context=dr1 get pods,svc -n minio-system 2>/dev/null | grep -v "No resources" || echo "  MinIO not found in dr1 cluster"
    echo "ü™£ S3 MinIO Status (DR2):"
    kubectl --context=dr2 get pods,svc -n minio-system 2>/dev/null | grep -v "No resources" || echo "  MinIO not found in dr2 cluster"
    echo ""

    # RESOURCE METRICS (if metrics-server available)
    echo -e "${GREEN}=== RESOURCE METRICS ===${NC}"
    echo "üìä Node Resources (DR1):"
    kubectl --context=dr1 top nodes 2>/dev/null || echo "  Metrics not available"
    echo "üìä Node Resources (DR2):"
    kubectl --context=dr2 top nodes 2>/dev/null || echo "  Metrics not available"
    echo ""

    # HELPFUL COMMANDS
    echo -e "${CYAN}=== QUICK ACCESS COMMANDS ===${NC}"
    echo "üîç Check VRG conditions: kubectl --context=dr1 describe vrg -n <namespace>"
    echo "üìã Check DRPC status: kubectl --context=hub describe drplacementcontrol -n <namespace>"
    echo "üìä Monitor DR operator logs: kubectl --context=dr1 logs -n ramen-system deployment/ramen-dr-cluster-operator -f"
    echo "ü™û Check RBD mirror status: kubectl --context=dr1 -n rook-ceph exec deployment/rook-ceph-tools -- rbd mirror pool status replicapool"
    echo "üíæ List Ceph pools: kubectl --context=dr1 -n rook-ceph exec deployment/rook-ceph-tools -- ceph osd pool ls"
    
    echo ""
    echo -e "${GREEN}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
}

# Function to display monitoring options
show_monitoring_options() {
    echo -e "${BLUE}üìä RamenDR Regional DR Monitoring Options:${NC}"
    echo ""
    echo "1. üèóÔ∏è  Cluster & Infrastructure Monitoring"
    echo "2. üì¶ Application & DR Resources Monitoring"  
    echo "3. üíæ Storage & VRG Monitoring"
    echo "4. ‚öôÔ∏è  Operators & CRDs Monitoring"
    echo "5. ü™û Ceph & RBD Mirroring Monitoring"
    echo "6. üîÑ Comprehensive All-in-One Monitoring"
    echo "7. üåê MinIO Console Access Setup"
    echo "8. üìã Show All Commands (for copy-paste)"
    echo "9. ‚ùì Help & Examples"
    echo ""
}

# Cluster monitoring
cluster_monitoring() {
    echo -e "${GREEN}üèóÔ∏è  Starting Cluster & Infrastructure Monitoring...${NC}"
    echo ""
    echo "This will monitor:"
    echo "  ‚Ä¢ Cluster contexts and connectivity"
    echo "  ‚Ä¢ RamenDR operator pods"
    echo "  ‚Ä¢ OCM components"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
    echo ""
    sleep 2
    
    watch -n 2 '
        echo "=== REGIONAL DR CLUSTERS ===" && 
        kubectl config get-contexts | head -n 1 && 
        kubectl config get-contexts | grep -E "(hub|dr1|dr2)" && 
        echo "" && 
        echo "=== RAMEN OPERATORS ===" && 
        kubectl --context=hub get pods -n ramen-system 2>/dev/null | head -3 && 
        kubectl --context=dr1 get pods -n ramen-system 2>/dev/null | head -3 && 
        kubectl --context=dr2 get pods -n ramen-system 2>/dev/null | head -3
    '
}

# Application monitoring  
app_monitoring() {
    echo -e "${GREEN}üì¶ Starting Application & DR Resources Monitoring...${NC}"
    echo ""
    echo "This will monitor:"
    echo "  ‚Ä¢ DRClusters and DRPolicies (Hub)"
    echo "  ‚Ä¢ VRGs, Pods, and PVCs (DR clusters)"
    echo "  ‚Ä¢ DRPC placement decisions"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
    echo ""
    sleep 2
    
    watch -n 3 '
        echo "=== DR RESOURCES (Hub) ===" && 
        kubectl --context=hub get drclusters,drpolicy,drplacementcontrol -A 2>/dev/null || echo "Not ready yet" && 
        echo "" && 
        echo "=== VRG & APPLICATIONS (DR1) ===" && 
        kubectl --context=dr1 get vrg,pods,pvc -A 2>/dev/null | head -8 || echo "Not ready yet" && 
        echo "" && 
        echo "=== VRG & APPLICATIONS (DR2) ===" && 
        kubectl --context=dr2 get vrg,pods,pvc -A 2>/dev/null | head -6 || echo "Not ready yet"
    '
}

# Storage monitoring
storage_monitoring() {
    echo -e "${GREEN}üíæ Starting Storage & VRG Monitoring...${NC}"
    echo ""
    echo "This will monitor:"
    echo "  ‚Ä¢ VRGs and VolumeReplications"
    echo "  ‚Ä¢ Ceph storage pools and classes"
    echo "  ‚Ä¢ Volume snapshots and replication classes"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
    echo ""
    sleep 2
    
    watch -n 5 '
        echo "=== STORAGE CLASSES ===" && 
        kubectl --context=dr1 get storageclass 2>/dev/null && 
        echo "" && 
        echo "=== VRG RESOURCES (DR1) ===" && 
        kubectl --context=dr1 get vrg,volumereplication -A 2>/dev/null || echo "VRG resources not ready" && 
        echo "" && 
        echo "=== VOLUME REPLICATION CLASSES ===" && 
        kubectl --context=dr1 get volumereplicationclass 2>/dev/null || echo "No VRC found" && 
        echo "" && 
        echo "=== CEPH BLOCK POOLS ===" && 
        kubectl --context=dr1 -n rook-ceph get cephblockpool 2>/dev/null || echo "No Ceph pools found"
    '
}

# Operators monitoring
operators_monitoring() {
    echo -e "${GREEN}‚öôÔ∏è  Starting Operators & CRDs Monitoring...${NC}"
    echo ""
    echo "This will monitor:"
    echo "  ‚Ä¢ RamenDR operators on all clusters"
    echo "  ‚Ä¢ RamenDR CRDs installation status"
    echo "  ‚Ä¢ CSI addons and external snapshotter"
    echo "  ‚Ä¢ Rook operators"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
    echo ""
    sleep 2
    
    watch -n 3 '
        echo "=== RAMENDR CRDS ===" && 
        kubectl --context=hub get crd | grep ramen && 
        echo "" && 
        echo "=== RAMENDR HUB OPERATOR ===" && 
        kubectl --context=hub get pods,deployments -n ramen-system 2>/dev/null | head -4 && 
        echo "" && 
        echo "=== RAMENDR DR1 OPERATOR ===" && 
        kubectl --context=dr1 get pods,deployments -n ramen-system 2>/dev/null | head -3 && 
        echo "" && 
        echo "=== CSI ADDONS ===" && 
        kubectl --context=dr1 get pods -n csi-addons-system 2>/dev/null | head -3 || echo "CSI addons not ready" && 
        echo "" && 
        echo "=== ROOK OPERATOR ===" && 
        kubectl --context=dr1 get pods -n rook-ceph | grep operator | head -3 || echo "Rook not ready"
    '
}

# Ceph and RBD mirroring monitoring
ceph_monitoring() {
    echo -e "${GREEN}ü™û Starting Ceph & RBD Mirroring Monitoring...${NC}"
    echo ""
    echo "This will monitor:"
    echo "  ‚Ä¢ Ceph cluster health"
    echo "  ‚Ä¢ RBD mirroring daemons"
    echo "  ‚Ä¢ Pool mirroring status"
    echo "  ‚Ä¢ OSD status"
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
    echo ""
    sleep 2
    
    watch -n 5 '
        echo "=== CEPH CLUSTERS ===" && 
        kubectl --context=dr1 -n rook-ceph get cephcluster 2>/dev/null && 
        kubectl --context=dr2 -n rook-ceph get cephcluster 2>/dev/null && 
        echo "" && 
        echo "=== RBD MIRROR DAEMONS ===" && 
        kubectl --context=dr1 -n rook-ceph get pods | grep rbd-mirror || echo "No RBD mirror on dr1" && 
        kubectl --context=dr2 -n rook-ceph get pods | grep rbd-mirror || echo "No RBD mirror on dr2" && 
        echo "" && 
        echo "=== CEPH HEALTH (DR1) ===" && 
        kubectl --context=dr1 -n rook-ceph exec deployment/rook-ceph-tools -- ceph status 2>/dev/null | head -10 || echo "Ceph tools not ready"
    '
}

# MinIO console setup
minio_console() {
    echo -e "${GREEN}üåê Setting up MinIO Console Access...${NC}"
    echo ""
    
    # Check which cluster has MinIO
    local minio_cluster=""
    for cluster in hub dr1 dr2; do
        if kubectl --context=$cluster get namespace minio-system >/dev/null 2>&1; then
            minio_cluster=$cluster
            break
        fi
    done
    
    if [ -n "$minio_cluster" ]; then
        echo "Found MinIO on cluster: $minio_cluster"
        
        # Kill existing port-forwards
        pkill -f "kubectl port-forward.*minio" >/dev/null 2>&1 || true
        
        echo "Starting MinIO console port-forwarding on cluster $minio_cluster..."
        kubectl --context=$minio_cluster port-forward -n minio-system service/minio 9001:9001 > /dev/null 2>&1 &
        sleep 3
        
        echo ""
        echo -e "${GREEN}‚úÖ MinIO Console Setup Complete!${NC}"
        echo ""
        echo "üåê Access URLs:"
        echo "  ‚Ä¢ Console: http://localhost:9001"
        echo "  ‚Ä¢ API: http://localhost:9000"
        echo ""
        echo "üîë Credentials:"
        echo "  ‚Ä¢ Username: minioadmin"
        echo "  ‚Ä¢ Password: minioadmin"
        echo ""
        echo "üì¶ Expected S3 Bucket: ramen-metadata"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  MinIO not found on any cluster${NC}"
    fi
}

# Show all commands for copy-paste
show_commands() {
    echo -e "${BLUE}üìã All Monitoring Commands (Copy-Paste Ready):${NC}"
    echo ""
    
    echo -e "${PURPLE}# Terminal 2: Cluster & Infrastructure Monitoring${NC}"
    echo 'watch -n 2 "
        echo \"=== REGIONAL DR CLUSTERS ===\" && 
        kubectl config get-contexts | head -n 1 && 
        kubectl config get-contexts | grep -E \"(hub|dr1|dr2)\" && 
        echo \"\" && 
        echo \"=== RAMEN OPERATORS ===\" && 
        kubectl --context=hub get pods -n ramen-system 2>/dev/null | head -3 && 
        kubectl --context=dr1 get pods -n ramen-system 2>/dev/null | head -3
    "'
    echo ""
    
    echo -e "${PURPLE}# Terminal 3: Application & DR Resources${NC}"
    echo 'watch -n 3 "
        echo \"=== DR RESOURCES (Hub) ===\" && 
        kubectl --context=hub get drclusters,drpolicy,drplacementcontrol -A 2>/dev/null || echo \"Not ready\" && 
        echo \"\" && 
        echo \"=== VRG & APPS (DR1) ===\" && 
        kubectl --context=dr1 get vrg,pods,pvc -A 2>/dev/null | head -8
    "'
    echo ""
    
    echo -e "${PURPLE}# Terminal 4: Storage & Ceph Monitoring${NC}"
    echo 'watch -n 5 "
        kubectl --context=dr1 get storageclass,volumereplicationclass 2>/dev/null && 
        kubectl --context=dr1 -n rook-ceph get cephblockpool,cephcluster 2>/dev/null | head -5
    "'
    echo ""
    
    echo -e "${PURPLE}# Terminal 5: MinIO Console${NC}"
    echo "./regional-dr-monitoring.sh # Choose option 7"
    echo ""
    
    echo -e "${PURPLE}# Comprehensive All-in-One Monitoring${NC}"
    echo "./regional-dr-monitoring.sh # Choose option 6"
}

# Help and examples
show_help() {
    echo -e "${BLUE}‚ùì RamenDR Regional DR Monitoring Help${NC}"
    echo ""
    echo -e "${PURPLE}üéØ Quick Start:${NC}"
    echo "  1. Ensure your regional DR environment is running"
    echo "  2. Run: ./regional-dr-monitoring.sh"
    echo "  3. Choose option 6 for comprehensive monitoring"
    echo "  4. Or use option 8 to copy commands to separate terminals"
    echo ""
    echo -e "${PURPLE}üìä Resource Explanations:${NC}"
    echo "  ‚Ä¢ vrg: VolumeReplicationGroup (RamenDR's core resource)"
    echo "  ‚Ä¢ volumereplication: CSI-level volume replication"
    echo "  ‚Ä¢ drclusters: Disaster Recovery cluster definitions"
    echo "  ‚Ä¢ drpolicy: DR policies and schedules"
    echo "  ‚Ä¢ drplacementcontrol: DR placement decisions"
    echo "  ‚Ä¢ cephcluster/cephblockpool: Ceph storage resources"
    echo "  ‚Ä¢ rbd-mirror: RBD mirroring daemon for cross-cluster replication"
    echo ""
    echo -e "${PURPLE}‚ö° Regional DR Tips:${NC}"
    echo "  ‚Ä¢ Monitor all 3 clusters: hub (management), dr1 (primary), dr2 (secondary)"
    echo "  ‚Ä¢ Check RBD mirror health for CSI replication"
    echo "  ‚Ä¢ VRG resources show protection status"
    echo "  ‚Ä¢ Use MinIO console to monitor S3 metadata backups"
    echo ""
    echo -e "${PURPLE}üîß Troubleshooting:${NC}"
    echo "  ‚Ä¢ If contexts not found: check drenv environment is running"
    echo "  ‚Ä¢ If no resources shown: operators may still be starting"
    echo "  ‚Ä¢ If Ceph issues: check rook-ceph namespace pods"
    echo "  ‚Ä¢ For RBD mirror status: exec into rook-ceph-tools pod"
}

# Main menu
main() {
    # Check contexts first
    check_contexts
    
    if [ $# -eq 1 ] && [ "$1" == "comprehensive" ]; then
        # Direct comprehensive monitoring without menu
        while true; do
            comprehensive_monitoring
            sleep 5
        done
    fi
    
    while true; do
        show_monitoring_options
        read -p "Choose an option (1-9) or 'q' to quit: " choice
        echo ""
        
        case $choice in
            1) cluster_monitoring ;;
            2) app_monitoring ;;
            3) storage_monitoring ;;
            4) operators_monitoring ;;
            5) ceph_monitoring ;;
            6) 
                echo -e "${GREEN}üîÑ Starting Comprehensive All-in-One Monitoring...${NC}"
                echo -e "${YELLOW}‚ö†Ô∏è  Press Ctrl+C to stop monitoring${NC}"
                sleep 2
                while true; do
                    comprehensive_monitoring
                    sleep 5
                done
                ;;
            7) minio_console ;;
            8) show_commands ;;
            9) show_help ;;
            q|Q) echo "Exiting..."; exit 0 ;;
            *) echo -e "${RED}‚ùå Invalid option. Please choose 1-9 or 'q'${NC}"; echo ;;
        esac
        
        if [ "$choice" != "7" ] && [ "$choice" != "8" ] && [ "$choice" != "9" ]; then
            echo ""
            echo -e "${YELLOW}Press any key to return to menu...${NC}"
            read -n 1 -s
            echo ""
        fi
    done
}

# Run main function
main "$@"